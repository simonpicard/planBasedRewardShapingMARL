@Article{paper4,
  author =	 {Sam Devlin and Daniel Kudenko},
  title =	 {Plan-Based Reward Shaping for Multi-Agent Reinforcement Learning},
  journal =	 {The Knowledge Engineering Review},
  year =	 2004,
  volume =	 {00},
  pages =	 {1-24}
}

@Book{rs,
  author =	 {Marek Grzes and Daniel Kudenko},
  title =	 {Reward Shaping and Mixed Resolution Function Approximation},
  publisher =	 {IGI Global},
  year =	 2011
}

@Article{etrace,
  author =   {Singh, S. P. and Sutton, R. S.},
  title =  {Reinforcement learning with replacing eligibility traces},
  journal =  {Machine Learning},
  year =   1996,
  volume =   {22},
  pages =  {123-158}
}

@Article{rs2,
  author =   {Andrew Y. Ng, Daishi Harada and Stuart J. Russell},
  title =  {Policy invariance under reward transformations : Theory and application to reward shaping},
  journal =  {ICML '99 Proceedings of the Sixteenth International Conference on Machine Learning},
  year =   1999,
  pages =  {278-287}

}

@inproceedings{SCpbrs,
  title={Using plan-based reward shaping to learn strategies in starcraft: Broodwar},
  author={Efthymiadis, Kyriakos and Kudenko, Daniel},
  booktitle={Computational Intelligence in Games (CIG), 2013 IEEE Conference on},
  pages={1--8},
  year={2013},
  organization={IEEE}
}